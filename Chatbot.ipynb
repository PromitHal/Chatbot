{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023caedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Chatbot-Copy1.ipynb',\n",
       " 'Chatbot.ipynb',\n",
       " 'intent.json',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101a1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "import json\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77498ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8748c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents=json.loads(open('intent.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327e23a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PROMIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827618d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greetings',\n",
       "   'patterns': ['hello',\n",
       "    'hi',\n",
       "    'hey',\n",
       "    'good day',\n",
       "    'greetings',\n",
       "    'whats up?',\n",
       "    'how is it going?'],\n",
       "   'responses': ['Hello',\n",
       "    'Hey!',\n",
       "    'How can I help you?',\n",
       "    'What can i do for you?',\n",
       "    'Hey Whats up?',\n",
       "    'Hello Darling',\n",
       "    'Hey ! How are you?']},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['cya',\n",
       "    'bye bye',\n",
       "    'bye',\n",
       "    'Goodbye',\n",
       "    'Tata',\n",
       "    'See you later',\n",
       "    'I am leaving',\n",
       "    'I have to go',\n",
       "    'I want to leave',\n",
       "    'Fuck off',\n",
       "    'Get lost',\n",
       "    'Stop talking now',\n",
       "    'Stop talking',\n",
       "    'cao',\n",
       "    'See ya',\n",
       "    'See you',\n",
       "    'Have a good day',\n",
       "    'tada',\n",
       "    'enough for today',\n",
       "    'now just stop it'],\n",
       "   'responses': ['Sad to see you leave :(',\n",
       "    'Bye! :*(',\n",
       "    'See you later',\n",
       "    'Talk to you later',\n",
       "    'Have a great day',\n",
       "    'Bye Bye',\n",
       "    'Tata']},\n",
       "  {'tag': 'age',\n",
       "   'patterns': ['how old',\n",
       "    'how old are you',\n",
       "    'how old is Promit',\n",
       "    'what is you age'],\n",
       "   'responses': ['I am a day old Still learning to be a human']}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a2d7429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['hello'], 'greetings'), (['hi'], 'greetings'), (['hey'], 'greetings'), (['good', 'day'], 'greetings'), (['greetings'], 'greetings'), (['whats', 'up', '?'], 'greetings'), (['how', 'is', 'it', 'going', '?'], 'greetings'), (['cya'], 'goodbye'), (['bye', 'bye'], 'goodbye'), (['bye'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Tata'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['I', 'am', 'leaving'], 'goodbye'), (['I', 'have', 'to', 'go'], 'goodbye'), (['I', 'want', 'to', 'leave'], 'goodbye'), (['Fuck', 'off'], 'goodbye'), (['Get', 'lost'], 'goodbye'), (['Stop', 'talking', 'now'], 'goodbye'), (['Stop', 'talking'], 'goodbye'), (['cao'], 'goodbye'), (['See', 'ya'], 'goodbye'), (['See', 'you'], 'goodbye'), (['Have', 'a', 'good', 'day'], 'goodbye'), (['tada'], 'goodbye'), (['enough', 'for', 'today'], 'goodbye'), (['now', 'just', 'stop', 'it'], 'goodbye'), (['how', 'old'], 'age'), (['how', 'old', 'are', 'you'], 'age'), (['how', 'old', 'is', 'Promit'], 'age'), (['what', 'is', 'you', 'age'], 'age')]\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "classes=[]\n",
    "documents=[]\n",
    "ignore_letters=['?','!','.',',']\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list=nltk.word_tokenize(pattern)\n",
    "        words.append(word_list)\n",
    "        documents.append((word_list,intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80cdcdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello'],\n",
       " ['hi'],\n",
       " ['hey'],\n",
       " ['good', 'day'],\n",
       " ['greetings'],\n",
       " ['whats', 'up', '?'],\n",
       " ['how', 'is', 'it', 'going', '?'],\n",
       " ['cya'],\n",
       " ['bye', 'bye'],\n",
       " ['bye'],\n",
       " ['Goodbye'],\n",
       " ['Tata'],\n",
       " ['See', 'you', 'later'],\n",
       " ['I', 'am', 'leaving'],\n",
       " ['I', 'have', 'to', 'go'],\n",
       " ['I', 'want', 'to', 'leave'],\n",
       " ['Fuck', 'off'],\n",
       " ['Get', 'lost'],\n",
       " ['Stop', 'talking', 'now'],\n",
       " ['Stop', 'talking'],\n",
       " ['cao'],\n",
       " ['See', 'ya'],\n",
       " ['See', 'you'],\n",
       " ['Have', 'a', 'good', 'day'],\n",
       " ['tada'],\n",
       " ['enough', 'for', 'today'],\n",
       " ['now', 'just', 'stop', 'it'],\n",
       " ['how', 'old'],\n",
       " ['how', 'old', 'are', 'you'],\n",
       " ['how', 'old', 'is', 'Promit'],\n",
       " ['what', 'is', 'you', 'age']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2d8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words=[]\n",
    "for row in range(len(words)):\n",
    "    for col in range(len(words[row])):\n",
    "        new_words.append(words[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d11d6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'hi',\n",
       " 'hey',\n",
       " 'good',\n",
       " 'day',\n",
       " 'greetings',\n",
       " 'whats',\n",
       " 'up',\n",
       " '?',\n",
       " 'how',\n",
       " 'is',\n",
       " 'it',\n",
       " 'going',\n",
       " '?',\n",
       " 'cya',\n",
       " 'bye',\n",
       " 'bye',\n",
       " 'bye',\n",
       " 'Goodbye',\n",
       " 'Tata',\n",
       " 'See',\n",
       " 'you',\n",
       " 'later',\n",
       " 'I',\n",
       " 'am',\n",
       " 'leaving',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'Fuck',\n",
       " 'off',\n",
       " 'Get',\n",
       " 'lost',\n",
       " 'Stop',\n",
       " 'talking',\n",
       " 'now',\n",
       " 'Stop',\n",
       " 'talking',\n",
       " 'cao',\n",
       " 'See',\n",
       " 'ya',\n",
       " 'See',\n",
       " 'you',\n",
       " 'Have',\n",
       " 'a',\n",
       " 'good',\n",
       " 'day',\n",
       " 'tada',\n",
       " 'enough',\n",
       " 'for',\n",
       " 'today',\n",
       " 'now',\n",
       " 'just',\n",
       " 'stop',\n",
       " 'it',\n",
       " 'how',\n",
       " 'old',\n",
       " 'how',\n",
       " 'old',\n",
       " 'are',\n",
       " 'you',\n",
       " 'how',\n",
       " 'old',\n",
       " 'is',\n",
       " 'Promit',\n",
       " 'what',\n",
       " 'is',\n",
       " 'you',\n",
       " 'age']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a838dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello hi hey good day greeting whats up how is it going cya bye bye bye goodbye tata see you later i am leaving i have to go i want to leave fuck off get lost stop talking now stop talking cao see ya see you have a good day tada enough for today now just stop it how old how old are you how old is promit what is you age\n"
     ]
    }
   ],
   "source": [
    "words=' '.join(word for word in new_words)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af4ef2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[lemmatizer.lemmatize(word.lower()) for word in new_words if word not in ignore_letters ]\n",
    "words=sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6698f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'age', 'am', 'are', 'bye', 'cao', 'cya', 'day', 'enough', 'for', 'fuck', 'get', 'go', 'going', 'good', 'goodbye', 'greeting', 'have', 'hello', 'hey', 'hi', 'how', 'i', 'is', 'it', 'just', 'later', 'leave', 'leaving', 'lost', 'now', 'off', 'old', 'promit', 'see', 'stop', 'tada', 'talking', 'tata', 'to', 'today', 'up', 'want', 'what', 'whats', 'ya', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7fe938",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35e465e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44e28abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=[]\n",
    "output_empty=[0]*len(classes)\n",
    "for document in documents:\n",
    "    bag=[]\n",
    "    word_patterns=document[0]\n",
    "    word_patterns=[lemmatizer.lemmatize(word.lower())for word in word_patterns]\n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_patterns else bag.append(0)\n",
    "    output_row=list(output_empty)\n",
    "    output_row[classes.index(document[1])]=1\n",
    "    training.append([bag,output_row])\n",
    "random.shuffle(training)\n",
    "training=np.array(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a50aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=list(training[:,0])\n",
    "train_y=list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46dcb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40f3ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128,input_shape=(len(train_x[0]),),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(65, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]),activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "824cbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "746d8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=tensorflow.keras.optimizers.Adam(lr=0.01,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf7c3de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 2/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 3/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 4/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 5/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 6/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 7/200\n",
      "7/7 - 0s - loss: 0.8846 - acc: 0.6452\n",
      "Epoch 8/200\n",
      "7/7 - 0s - loss: 0.8847 - acc: 0.6452\n",
      "Epoch 9/200\n",
      "7/7 - 0s - loss: 0.8846 - acc: 0.6452\n",
      "Epoch 10/200\n",
      "7/7 - 0s - loss: 0.8855 - acc: 0.6452\n",
      "Epoch 11/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 12/200\n",
      "7/7 - 0s - loss: 0.8855 - acc: 0.6452\n",
      "Epoch 13/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 14/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 15/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 16/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 17/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 18/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 19/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 20/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 21/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 22/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 23/200\n",
      "7/7 - 0s - loss: 0.8867 - acc: 0.6452\n",
      "Epoch 24/200\n",
      "7/7 - 0s - loss: 0.8847 - acc: 0.6452\n",
      "Epoch 25/200\n",
      "7/7 - 0s - loss: 0.8860 - acc: 0.6452\n",
      "Epoch 26/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 27/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 28/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 29/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 30/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 31/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 32/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 33/200\n",
      "7/7 - 0s - loss: 0.8852 - acc: 0.6452\n",
      "Epoch 34/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 35/200\n",
      "7/7 - 0s - loss: 0.8827 - acc: 0.6452\n",
      "Epoch 36/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 37/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 38/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 39/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 40/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 41/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 42/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 43/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 44/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 45/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 46/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 47/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 48/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 49/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 50/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 51/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 52/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 53/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 54/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 55/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 56/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 57/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 58/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 59/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 60/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 61/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 62/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 63/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 64/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 65/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 66/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 67/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 68/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 69/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 70/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 71/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 72/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 73/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 74/200\n",
      "7/7 - 0s - loss: 0.8848 - acc: 0.6452\n",
      "Epoch 75/200\n",
      "7/7 - 0s - loss: 0.8847 - acc: 0.6452\n",
      "Epoch 76/200\n",
      "7/7 - 0s - loss: 0.8846 - acc: 0.6452\n",
      "Epoch 77/200\n",
      "7/7 - 0s - loss: 0.8849 - acc: 0.6452\n",
      "Epoch 78/200\n",
      "7/7 - 0s - loss: 0.8850 - acc: 0.6452\n",
      "Epoch 79/200\n",
      "7/7 - 0s - loss: 0.8846 - acc: 0.6452\n",
      "Epoch 80/200\n",
      "7/7 - 0s - loss: 0.8861 - acc: 0.6452\n",
      "Epoch 81/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 82/200\n",
      "7/7 - 0s - loss: 0.8849 - acc: 0.6452\n",
      "Epoch 83/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 84/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 85/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 86/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 87/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 88/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 89/200\n",
      "7/7 - 0s - loss: 0.8849 - acc: 0.6452\n",
      "Epoch 90/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 91/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 92/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 93/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 94/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 95/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 96/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 97/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 98/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 99/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 100/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 101/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 102/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 103/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 104/200\n",
      "7/7 - 0s - loss: 0.8848 - acc: 0.6452\n",
      "Epoch 105/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 106/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 107/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 108/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 109/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 110/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 111/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 112/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 113/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 114/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 115/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 116/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 117/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 118/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 119/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 120/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 121/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 122/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 123/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 124/200\n",
      "7/7 - 0s - loss: 0.8849 - acc: 0.6452\n",
      "Epoch 125/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 126/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 127/200\n",
      "7/7 - 0s - loss: 0.8849 - acc: 0.6452\n",
      "Epoch 128/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 129/200\n",
      "7/7 - 0s - loss: 0.8845 - acc: 0.6452\n",
      "Epoch 130/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 131/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 132/200\n",
      "7/7 - 0s - loss: 0.8846 - acc: 0.6452\n",
      "Epoch 133/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 134/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 135/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 136/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 137/200\n",
      "7/7 - 0s - loss: 0.8841 - acc: 0.6452\n",
      "Epoch 138/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 139/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 140/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 141/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 142/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 143/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 144/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 145/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 146/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 147/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 148/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 149/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 150/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 151/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 152/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 153/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 154/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 155/200\n",
      "7/7 - 0s - loss: 0.8841 - acc: 0.6452\n",
      "Epoch 156/200\n",
      "7/7 - 0s - loss: 0.8829 - acc: 0.6452\n",
      "Epoch 157/200\n",
      "7/7 - 0s - loss: 0.8829 - acc: 0.6452\n",
      "Epoch 158/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 159/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 160/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 162/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 163/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 164/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 165/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 166/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 167/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 168/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 169/200\n",
      "7/7 - 0s - loss: 0.8845 - acc: 0.6452\n",
      "Epoch 170/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 171/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 172/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 173/200\n",
      "7/7 - 0s - loss: 0.8842 - acc: 0.6452\n",
      "Epoch 174/200\n",
      "7/7 - 0s - loss: 0.8833 - acc: 0.6452\n",
      "Epoch 175/200\n",
      "7/7 - 0s - loss: 0.8841 - acc: 0.6452\n",
      "Epoch 176/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 177/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 178/200\n",
      "7/7 - 0s - loss: 0.8841 - acc: 0.6452\n",
      "Epoch 179/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 180/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 181/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 182/200\n",
      "7/7 - 0s - loss: 0.8830 - acc: 0.6452\n",
      "Epoch 183/200\n",
      "7/7 - 0s - loss: 0.8834 - acc: 0.6452\n",
      "Epoch 184/200\n",
      "7/7 - 0s - loss: 0.8831 - acc: 0.6452\n",
      "Epoch 185/200\n",
      "7/7 - 0s - loss: 0.8845 - acc: 0.6452\n",
      "Epoch 186/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 187/200\n",
      "7/7 - 0s - loss: 0.8844 - acc: 0.6452\n",
      "Epoch 188/200\n",
      "7/7 - 0s - loss: 0.8846 - acc: 0.6452\n",
      "Epoch 189/200\n",
      "7/7 - 0s - loss: 0.8843 - acc: 0.6452\n",
      "Epoch 190/200\n",
      "7/7 - 0s - loss: 0.8840 - acc: 0.6452\n",
      "Epoch 191/200\n",
      "7/7 - 0s - loss: 0.8837 - acc: 0.6452\n",
      "Epoch 192/200\n",
      "7/7 - 0s - loss: 0.8832 - acc: 0.6452\n",
      "Epoch 193/200\n",
      "7/7 - 0s - loss: 0.8839 - acc: 0.6452\n",
      "Epoch 194/200\n",
      "7/7 - 0s - loss: 0.8838 - acc: 0.6452\n",
      "Epoch 195/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 196/200\n",
      "7/7 - 0s - loss: 0.8841 - acc: 0.6452\n",
      "Epoch 197/200\n",
      "7/7 - 0s - loss: 0.8841 - acc: 0.6452\n",
      "Epoch 198/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n",
      "Epoch 199/200\n",
      "7/7 - 0s - loss: 0.8835 - acc: 0.6452\n",
      "Epoch 200/200\n",
      "7/7 - 0s - loss: 0.8836 - acc: 0.6452\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(np.array(train_x),np.array(train_y),epochs=200,batch_size=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b5fa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=pickle.load(open('words.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b17c1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words=nltk.word_tokenize(sentence)\n",
    "    sentence_words=[lemmatizer.lemmatize(word)for word in sentence_words]\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97111dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence):\n",
    "    sentence_words=clean_up_sentence(sentence)\n",
    "    bag=[0]*len(words)\n",
    "    for w in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word==w:\n",
    "                bag[i]=1\n",
    "    return np.array(bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adcb90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence):\n",
    "    bow=bag_of_words(sentence)\n",
    "    res=model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESH=0.25\n",
    "    result=[[i,r] for i,r in enumerate(res) if r>ERROR_THRESH]\n",
    "    result.sort(key=lambda x: x[1],reverse=True)\n",
    "    return_list =[]\n",
    "    for r in results:\n",
    "        return_result.append({'intent':classes[r[0]],'probability':str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "429afc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 31 but received input with shape [None, 47]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5960/1405764852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mintents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5960/2902469510.py\u001b[0m in \u001b[0;36mpredict_class\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbag_of_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mERROR_THRESH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mERROR_THRESH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\PROMIT\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 31 but received input with shape [None, 47]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message=input(\"\")\n",
    "    ints=predict_class(message)\n",
    "    res=get_response(ints,intents)\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
